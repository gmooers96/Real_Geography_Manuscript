{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script to preprocess the data is:\n",
    "\n",
    "preprocess_RG.py\n",
    "\n",
    "This python script will scale all the variables of interest, stack them together, and combine the latitude, longitude, and time dimensions into one dimension called \"sample\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify what variables you want in your neural network input and ouput layers through the yml file:\n",
    "\n",
    "SPCAM5.yml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You simply add or remove the variables to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs: [TBP, QBP, PS, SOLIN, SHFLX, LHFLX]\n",
    "outputs: [PTTEND, PTEQ, FSNT, FSNS, FLNT, FLNS, PRECT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full command to preprocess the training data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 /fast/gmooers/Real_Geography_Manuscript/preprocess_RG.py --config_file /fast/gmooers/Real_Geography_Manuscript/SPCAM5.yml --in_dir /DFS-L/DATA/pritchard/gmooers/Workflow/SPCAM_DATA/SPCAM5/2_Degree_Res/ --aqua_names TimestepOutput_Neuralnet_SPCAM_216.cam.h1.2014* --out_dir /fast/gmooers/Real_Geography_Manuscript/Preprocessed_Data/Full_Year_2021/ --out_pref full_physics_essentials_train_month01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broken down into pieces the additional arguments refer to:\n",
    "    \n",
    "--in_dir :  Where your raw (unprocessed) simulation data is \n",
    "\n",
    "--aqua_names : The names of the netcdf files of unprocessed data you want to include in training data (probably the year/years you want)\n",
    "\n",
    "--out_dir : Where you want to put your preprocessed training data after you finish preporcessing the data\n",
    "\n",
    "--out_pref : What you want to call your preprocessed training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation/Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will want to use the same command above for validation (or testing) dataexpect you will want one additional argument to ensure the validation data is normalized the same way the training data is:\n",
    "\n",
    "--ext_norm : {pathway to normalization file create by the command to train the data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a sample script to train a simple feed-forward network. Most of the hyper-parameters are hard-coded in (activation function, number of layers, layer width, ect...) and can be adjusted as needed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep_Training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the script you'll want to change the path to the training and validation data (line 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/fast/gmooers/Preprocessed_Data/7_Years_Spaced/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you changed the name in the --out_pref argument you will need to change lines in the Data_Generator() arguments as well (18-40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    data_dir=DATADIR, \n",
    "    feature_fn='full_physics_essentials_train_month01_shuffle_features.nc',\n",
    "    target_fn='full_physics_essentials_train_month01_shuffle_targets.nc',\n",
    "    batch_size=512,\n",
    "    norm_fn='full_physics_essentials_train_month01_norm.nc',\n",
    "    fsub='feature_means', \n",
    "    fdiv='feature_stds', \n",
    "    tmult='target_conv',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_gen = DataGenerator(\n",
    "    data_dir=DATADIR, \n",
    "    feature_fn='full_physics_essentials_valid_month02_features.nc',\n",
    "    target_fn='full_physics_essentials_valid_month02_targets.nc',\n",
    "    batch_size=512,\n",
    "    norm_fn='full_physics_essentials_train_month01_norm.nc',  # SAME NORMALIZATION FILE!\n",
    "    fsub='feature_means', \n",
    "    fdiv='feature_stds', \n",
    "    tmult='target_conv',\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard information can be removed on lines 107, 23, 124 for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change where you want to save the trained model (.h5 file) and loss curves on lines 129, 152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file to generate neural network predictions from the training data is:\n",
    "\n",
    "Model_Predictions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you will want to change the path to the data directory and if necessary the names of the validation data (lines 31-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = 'Preprocessed_Data/RG_Spaced_10_Years/'\n",
    "\n",
    "\n",
    "\n",
    "valid_gen = DataGenerator(\n",
    "    data_dir=DATADIR, \n",
    "    feature_fn='full_physics_essentials_test_month02_features.nc',\n",
    "    target_fn='full_physics_essentials_test_month02_targets.nc',\n",
    "    batch_size=512,\n",
    "    norm_fn='full_physics_essentials_train_month01_norm.nc',  # SAME NORMALIZATION FILE!\n",
    "    fsub='feature_means', \n",
    "    fdiv='feature_stds', \n",
    "    tmult='target_conv',\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the trained model (line 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Models/8_Years_Linear.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test data (line 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'Preprocessed_Data/RG_Spaced_10_Years/full_physics_essentials_test_month02_features.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally save the model predictions (line 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myds.to_netcdf('Models/Test_Final_Linear_DNN_Year.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick way is to look at how well the neural network emulates a vertical cross-section of the atmosphere. You can get those $R^2$ values in the script\n",
    "\n",
    "https://github.com/gmooers96/RG_Manuscript_Revised/blob/main/Post_Processing/Figure_1_2_3/Lat_Pressure_Timestep_R2_Heating.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll again want to change the filepaths for the model predictions and test data you generated. In the test data (axis 2) 0-30 are heating, 30-60 are moistening, and 61 is rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"/fast/gmooers/Real_Geography_Manuscript/Preprocessed_Data/RG_Spaced_10_Years/full_physics_essentials_test_month02_targets.nc\"\n",
    "ds = xr.open_dataset(path_to_file)\n",
    "truths = ds.targets[:, :30].values\n",
    "lons = ds.lon.values\n",
    "lats = ds.lat.values\n",
    "print('halfway')\n",
    "path_to_file = \"/fast/gmooers/Real_Geography_Manuscript/Models/Final_Sherpa_DNN_Annual.nc\"\n",
    "ds = xr.open_dataset(path_to_file)\n",
    "features = ds.Prediction[:, :30]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. the the code above extracts heating predictions from the neural network and truths from the spcam data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have the (2D) $R^2$ values you can take the the .npy file of those from the script above and then go to:\n",
    "\n",
    "https://zenodo.org/record/4558716\n",
    "\n",
    "And retrieve the .npy files for latitude (x) and pressure (z) coordinates to visualize the plot properly.\n",
    "\n",
    "\"X_Coords.npy\"\n",
    "\"Z_Coords.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An exmaple of a script to visualize the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.pcolor(X_Coords, Z_Coords, R2, cmap = 'Blues', vmin = 0, vmax = 1.0,  rasterized=True)\n",
    "ax.contour(X_Coords, Z_Coords, R2, [0.7], colors='pink', linewidths=[4])\n",
    "ax.contour(X_Coords, Z_Coords, R2, [0.9], colors='orange', linewidths=[4])\n",
    "ax.set_title(\"(g) Best Real Geography Heating\", fontsize = fz*0.9)\n",
    "ax.set_ylim(ax[3,0].get_ylim()[::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
