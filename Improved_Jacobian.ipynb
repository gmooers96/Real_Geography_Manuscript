{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "from data_generator import *\n",
    "from models import *\n",
    "\n",
    "#shouldn't need on a local computer?\n",
    "from utils import limit_mem\n",
    "\n",
    "#Module to save and load models\n",
    "import h5py\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import time\n",
    "#added by Griffin\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "from tensorflow.python.ops.parallel_for.gradients import batch_jacobian\n",
    "from tensorflow.python.ops.parallel_for.gradients import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "WARNING:tensorflow:From /fast/gmooers/Real_Geography_Manuscript/utils.py:237: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /fast/gmooers/Real_Geography_Manuscript/utils.py:239: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Generator will have 41126400 samples in 80325 batches\n",
      "Features have shape 64; targets have shape 65\n",
      "WARNING:tensorflow:From /export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "(41126400, 64)\n",
      "files imported\n"
     ]
    }
   ],
   "source": [
    "output_vector = 65\n",
    "input_vector = 64\n",
    "print('Starting')\n",
    "\n",
    "\n",
    "#If running on the GPU or GPU-shared partition uncomment\n",
    "limit_mem()\n",
    "\n",
    "\n",
    "DATADIR = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/'\n",
    "\n",
    "\n",
    "\n",
    "valid_gen = DataGenerator(\n",
    "    data_dir=DATADIR, \n",
    "    feature_fn='full_physics_essentials_valid_month02_features.nc',\n",
    "    target_fn='full_physics_essentials_valid_month02_targets.nc',\n",
    "    batch_size=512,\n",
    "    norm_fn='full_physics_essentials_train_month01_norm.nc',  # SAME NORMALIZATION FILE!\n",
    "    fsub='feature_means', \n",
    "    fdiv='feature_stds', \n",
    "    tmult='target_conv',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "fsub = valid_gen.feature_norms[0]\n",
    "fdiv = valid_gen.feature_norms[1]\n",
    "tsub = valid_gen.target_norms[0]\n",
    "tdiv = valid_gen.target_norms[1]\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('/fast/gmooers/Models/ContinentModels/second_round_model.h5')\n",
    "\n",
    "path_to_file = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/full_physics_essentials_valid_month02_features.nc'\n",
    "real_ds = xr.open_dataset(path_to_file)\n",
    "features = real_ds.features[:, :].values\n",
    "print(features.shape)\n",
    "\n",
    "\n",
    "path_to_file = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/full_physics_essentials_valid_month02_targets.nc'\n",
    "real_ds = xr.open_dataset(path_to_file)\n",
    "targets = real_ds.targets[:, :].values\n",
    "print('files imported')\n",
    "model_data = np.zeros(shape=(len(features), output_vector))\n",
    "model_data[:,:] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53995921/getting-keras-predictions-as-a-tensor-graph-for-use-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/44274701/make-predictions-using-a-tensorflow-graph-from-a-keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was Tensor(\"Const_5:0\", shape=(1, 64), dtype=float32) which was passed to the feed with key Tensor(\"input_1:0\", shape=(?, 64), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9647c963a8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_tensor_ph\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m## This works without error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/home/gmooers/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                             \u001b[0;34m'For reference, the tensor object was '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' which was passed to the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                             'feed with key ' + str(feed) + '.')\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m           \u001b[0msubfeed_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was Tensor(\"Const_5:0\", shape=(1, 64), dtype=float32) which was passed to the feed with key Tensor(\"input_1:0\", shape=(?, 64), dtype=float32)."
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model(\"model.h5\")\n",
    "model_output = model.output\n",
    "model_input = model.input\n",
    "new_tensor_ph = tf.placeholder(tf.float32, [None, 1])\n",
    "new_output = tf.multiply(model_output, new_tensor_ph)\n",
    "#x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "f = features[0]\n",
    "f=f.reshape(-1,1)\n",
    "x = np.reshape(f, (1,64))\n",
    "f = (x-fsub)/fdiv\n",
    "sess = tf.keras.backend.get_session() \n",
    "f = tf.convert_to_tensor(f)\n",
    "prediction = sess.run(new_output, feed_dict={model.input:f,new_tensor_ph :[[4]]})\n",
    "print(prediction)\n",
    "## This works without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "something = model(x_init_value)\n",
    "print(something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "f = features[0]\n",
    "f=f.reshape(-1,1)\n",
    "x = np.reshape(f, (1,64))\n",
    "x_init_value = (x-fsub)/fdiv\n",
    "x_placeholder =  tf.placeholder(tf.float32)\n",
    "x_var = tf.Variable(x_init_value, dtype=tf.float32)\n",
    "\n",
    "# Check calling my_model\n",
    "assign_step = tf.assign(x_var, x_placeholder)\n",
    "sess.run(assign_step, feed_dict={x_placeholder: x_init_value})\n",
    "model_output = model(x_var) # This simple step is all I wanted!\n",
    "sess.run(model_output) # This outputs my_model's predicted value for input x_init_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(x, my_model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = jacobian(my_model.output, my_model.input)\n",
    "    J = sess.run(jac, feed_dict={my_model.input: x.astype(np.float32)[None]})\n",
    "    return J.squeeze()\n",
    "\n",
    "def get_batch_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = batch_jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)})\n",
    "    return J.squeeze()\n",
    "\n",
    "get_jacobian(f, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootleg_jacobian(A, b):\n",
    "    dotProduct = A.dot(b)\n",
    "    ans = np.zeros((A.shape[0], A.shape[1], dotProduct.shape[0], dotProduct.shape[1]))\n",
    "    for l in range(A.shape[0]):\n",
    "        i = 0\n",
    "        for k in range(A.shape[1]):\n",
    "            ans[l][k][l][:] = b[i][:]\n",
    "            i = i + 1\n",
    "    return ans\n",
    "\n",
    "def vect_jacobian(A,b):\n",
    "\n",
    "    dotProduct = A.dot(b)\n",
    "    ans = np.zeros((A.shape[0], A.shape[1], dotProduct.shape[0], dotProduct.shape[1]))\n",
    "    L = list(range(A.shape[0]))\n",
    "    ans[L,:,L,:] = b\n",
    "    return ans\n",
    "\n",
    "#r = vect_jacobian(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = features[0]\n",
    "f=f.reshape(-1,1)\n",
    "x = np.reshape(f, (1,64))\n",
    "f = (x-fsub)/fdiv\n",
    "p = model.predict_on_batch(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(f))\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,65) and (1,64) not aligned: 65 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5a58626c2ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvect_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-22f5615b41c9>\u001b[0m in \u001b[0;36mvect_jacobian\u001b[0;34m(A, b)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvect_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdotProduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdotProduct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdotProduct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,65) and (1,64) not aligned: 65 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "vect_jacobian(p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "J = np.zeros((65, 64))\n",
    "#x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "#f = (x_tf-fsub)/fdiv\n",
    "with tf.GradientTape() as tape:\n",
    "    #x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "    x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "    tape.watch(x_tf)\n",
    "    f = (x_tf-fsub)/fdiv\n",
    "    print(type(f))\n",
    "   # p = tf.convert_to_tensor(model.predict_on_batch(f))\n",
    "    #p = model.predict_on_batch(f)\n",
    "    p = model.predict(f, steps=1)\n",
    "    print(type(p))\n",
    "    #print(fgdfdfggf)\n",
    "    #print(f.shape)\n",
    "    #pred = (p/tdiv)+tsub\n",
    "    #print(type(p))\n",
    "    #print(p.shape)\n",
    "    #pred = tf.convert_to_tensor(pred)\n",
    "    #print(type(pred))\n",
    "    #out_i = pred[0, 0]\n",
    "    #print(out_i*10000,0)\n",
    "\n",
    "grads = tape.jacobian(p, f)\n",
    "print(grads)\n",
    "#J[i, :] = grads/(fdiv*cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J=jacobian(p,f)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingExample = np.random.random((1,8))\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "evaluated_gradients = sess.run(gradients,feed_dict={model.input:trainingExample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_tensorflow(x):    \n",
    "    jacobian_matrix = []\n",
    "    for m in range(65):\n",
    "        print(m)\n",
    "        # We iterate over the M elements of the output vector\n",
    "        grad_func = tf.gradients(model.output[:, m], model.input)\n",
    "        gradients = sess.run(grad_func, feed_dict={model.input: x.reshape((1, x.size))})\n",
    "        jacobian_matrix.append(gradients[0][0,:])\n",
    "    return np.array(jacobian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "(65, 64)\n",
      "[[-7.67039601e-03  5.11548575e-03 -3.89819936e-04 ...  6.52137026e-02\n",
      "  -1.61790904e-02  2.91623324e-02]\n",
      " [-5.43078873e-03  2.78798304e-03 -7.36124639e-05 ...  5.11873886e-02\n",
      "  -1.55727854e-02  2.63065957e-02]\n",
      " [ 1.37523958e-03 -2.88796000e-04 -9.33522708e-04 ...  3.48145068e-02\n",
      "   4.39121388e-03  1.24364896e-02]\n",
      " ...\n",
      " [-8.97872611e-04 -5.32480329e-03 -9.10913339e-04 ...  1.28090149e-03\n",
      "   1.45285027e-02  2.63195448e-02]\n",
      " [-1.12135269e-04  7.58875976e-04 -1.84966868e-03 ... -1.37105742e-02\n",
      "   1.26841869e-02  5.02925599e-04]\n",
      " [ 1.58913119e-03  1.26594165e-02 -1.26897758e-02 ... -6.26130495e-03\n",
      "   2.37920275e-03 -2.72885915e-02]]\n"
     ]
    }
   ],
   "source": [
    "jaboc = jacobian_tensorflow(features[0])\n",
    "print(jaboc.shape)\n",
    "print(jaboc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
