{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/gmooers/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: \n",
      "The dedent function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use inspect.cleandoc instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import xarray as xr\n",
    "import dask\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import ticker\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from statistics import mode\n",
    "from matplotlib import transforms\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "bm = Basemap()\n",
    "import netCDF4\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files imported\n"
     ]
    }
   ],
   "source": [
    "path_to_file = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/full_physics_essentials_valid_month02_targets.nc'\n",
    "real_ds = xr.open_dataset(path_to_file)\n",
    "\n",
    "path_to_file = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Models/Good_July.nc'\n",
    "test_ds = xr.open_dataset(path_to_file)\n",
    "\n",
    "print('files imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41126400, 65)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_ds.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_real_ds = real_ds.targets[:96*96*144, :30].values\n",
    "\n",
    "heat_test_ds = test_ds.Prediction[:96*96*144, :30].values\n",
    "\n",
    "times = real_ds.time.values\n",
    "\n",
    "lats = real_ds.lat.values\n",
    "\n",
    "lons = real_ds.lon.values\n",
    "\n",
    "x = 144\n",
    "y = 96\n",
    "z = 30\n",
    "t = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_targets = np.zeros(shape=(x, y, t, z))\n",
    "reconstructed_features = np.zeros(shape=(x, y, t, z))\n",
    "count = 0\n",
    "for i in range(t):\n",
    "    for j in range(y):\n",
    "        for k in range(x):\n",
    "            #A = targets_heat[count]\n",
    "            #B = features_heat[count]\n",
    "            A = heat_real_ds[count]\n",
    "            B = heat_test_ds[count]\n",
    "            reconstructed_targets[k, j, i, :] = A\n",
    "            reconstructed_features[k, j, i, :] = B\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = sess.run(grad_func, feed_dict={model.input: x.reshape((1, x.size))})\n",
    "        jacobian_matrix.append(gradients[0][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_tensorflow(x):    \n",
    "    jacobian_matrix = []\n",
    "    for m in range(M):\n",
    "        # We iterate over the M elements of the output vector\n",
    "        grad_func = tf.gradients(model.output[:, m], model.input)\n",
    "        gradients = sess.run(grad_func, feed_dict={model.input: x.reshape((1, x.size))})\n",
    "        jacobian_matrix.append(gradients[0][0,:])\n",
    "    return np.array(jacobian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)[None]})\n",
    "    return J.squeeze()\n",
    "def get_batch_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = batch_jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)})\n",
    "    return J.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
