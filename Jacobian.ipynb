{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "from data_generator import *\n",
    "from models import *\n",
    "\n",
    "#shouldn't need on a local computer?\n",
    "from utils import limit_mem\n",
    "\n",
    "#Module to save and load models\n",
    "import h5py\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import time\n",
    "#added by Griffin\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "from tensorflow.python.ops.parallel_for.gradients import batch_jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(z):\n",
    "    #y = x**10*K\n",
    "    #y = K.exp(z)\n",
    "    y = z**10\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 15:22:45.838151 140272943224640 deprecation_wrapper.py:119] From /fast/gmooers/Real_Geography_Manuscript/utils.py:237: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1110 15:22:45.840032 140272943224640 deprecation_wrapper.py:119] From /fast/gmooers/Real_Geography_Manuscript/utils.py:239: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:22:49.757701 140272943224640 deprecation.py:506] From /export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1110 15:22:49.759760 140272943224640 deprecation.py:506] From /export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1110 15:22:49.762934 140272943224640 deprecation.py:506] From /export/home/gmooers/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator will have 41126400 samples in 80325 batches\n",
      "Features have shape 64; targets have shape 65\n",
      "(41126400, 64)\n",
      "files imported\n"
     ]
    }
   ],
   "source": [
    "output_vector = 65\n",
    "input_vector = 64\n",
    "print('Starting')\n",
    "\n",
    "\n",
    "#If running on the GPU or GPU-shared partition uncomment\n",
    "limit_mem()\n",
    "\n",
    "\n",
    "DATADIR = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/'\n",
    "\n",
    "\n",
    "\n",
    "valid_gen = DataGenerator(\n",
    "    data_dir=DATADIR, \n",
    "    feature_fn='full_physics_essentials_valid_month02_features.nc',\n",
    "    target_fn='full_physics_essentials_valid_month02_targets.nc',\n",
    "    batch_size=512,\n",
    "    norm_fn='full_physics_essentials_train_month01_norm.nc',  # SAME NORMALIZATION FILE!\n",
    "    fsub='feature_means', \n",
    "    fdiv='feature_stds', \n",
    "    tmult='target_conv',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "fsub = valid_gen.feature_norms[0]\n",
    "fdiv = valid_gen.feature_norms[1]\n",
    "tsub = valid_gen.target_norms[0]\n",
    "tdiv = valid_gen.target_norms[1]\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('/fast/gmooers/Models/ContinentModels/second_round_model.h5')\n",
    "\n",
    "path_to_file = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/full_physics_essentials_valid_month02_features.nc'\n",
    "real_ds = xr.open_dataset(path_to_file)\n",
    "features = real_ds.features[:, :].values\n",
    "print(features.shape)\n",
    "\n",
    "\n",
    "path_to_file = '/DFS-L/DATA/pritchard/gmooers/RG_Paper/RG_DATA/Preprocessed_Data/One_Month_July/full_physics_essentials_valid_month02_targets.nc'\n",
    "real_ds = xr.open_dataset(path_to_file)\n",
    "targets = real_ds.targets[:, :].values\n",
    "print('files imported')\n",
    "model_data = np.zeros(shape=(len(features), output_vector))\n",
    "model_data[:,:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)[None]})\n",
    "    return J.squeeze()\n",
    "def get_batch_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = batch_jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)})\n",
    "    return J.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(model,inp,sample_index,gen_obj,fdiv,cf):\n",
    "# model is the neural network model from inp to out\n",
    "# inp is the input x generator from the generator (object = gen_obj)\n",
    "# sample_index is the reference number of the sample for x\n",
    "# x.shape = (#sample,#inputs) so we are evaluating the gradient of\n",
    "# y(sample_index,:) with respect to x(sample_index,:)\n",
    "    J = np.zeros((gen_obj.target_shape, gen_obj.feature_shape))\n",
    "    for i in range(gen_obj.target_shape):\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_tf = tf.convert_to_tensor(np.expand_dims(x[sample_index,:],axis=0) )\n",
    "            tape.watch(x_tf)\n",
    "            pred = model(x_tf)\n",
    "            out_i = pred[0, i]\n",
    "        grads = tape.gradient(out_i, x_tf).numpy()\n",
    "        J[i, :] = grads/(fdiv*cf)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_433:0\", shape=(2, 2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[4, 2],[1, 3]], dtype=tf.dtypes.float32) \n",
    "with tf.GradientTape() as gg: \n",
    "    gg.watch(x) \n",
    "    y = x * x * x \n",
    "   # Computing first order jacobian \n",
    "first_order = gg.jacobian(y, x)\n",
    "print(first_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(1, 64)\n",
      "Tensor(\"Reshape_464:0\", shape=(1, 64, 1, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "J = np.zeros((65, 64))\n",
    "#x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "#f = (x_tf-fsub)/fdiv\n",
    "with tf.GradientTape() as tape:\n",
    "    #x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "    x_tf = tf.convert_to_tensor(np.expand_dims(features[0,:],axis=0))\n",
    "    tape.watch(x_tf)\n",
    "    f = (x_tf-fsub)/fdiv\n",
    "   # p = tf.convert_to_tensor(model.predict_on_batch(f))\n",
    "    p = f*f\n",
    "    #print(f.shape)\n",
    "    #pred = (p/tdiv)+tsub\n",
    "    print(type(p))\n",
    "    print(p.shape)\n",
    "    #pred = tf.convert_to_tensor(pred)\n",
    "    #print(type(pred))\n",
    "    #out_i = pred[0, 0]\n",
    "    #print(out_i*10000,0)\n",
    "\n",
    "#grads = tape.jacobian(p, f)\n",
    "print(grads)\n",
    "#J[i, :] = grads/(fdiv*cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_inbound_node',\n",
       " '_add_unique_metric_name',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_all_metrics_tensors',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_base_init',\n",
       " '_cache_output_metric_attributes',\n",
       " '_call_convention',\n",
       " '_call_fn_args',\n",
       " '_call_metric_fn',\n",
       " '_callable_losses',\n",
       " '_check_trainable_weights_consistency',\n",
       " '_checkpoint_dependencies',\n",
       " '_ckpt_saved_epoch',\n",
       " '_clear_losses',\n",
       " '_cloning',\n",
       " '_collected_trainable_weights',\n",
       " '_compile_distribution',\n",
       " '_compile_eagerly',\n",
       " '_compile_metric_functions',\n",
       " '_compile_metrics',\n",
       " '_compile_metrics_names',\n",
       " '_compile_metrics_tensors',\n",
       " '_compile_weighted_metrics',\n",
       " '_compile_weights_loss_and_weighted_metrics',\n",
       " '_compute_output_and_mask_jointly',\n",
       " '_deferred_dependencies',\n",
       " '_determine_call_convention',\n",
       " '_distributed_function_cache',\n",
       " '_distributed_model_cache',\n",
       " '_distribution_standardize_user_data',\n",
       " '_distribution_strategy',\n",
       " '_dtype',\n",
       " '_dynamic',\n",
       " '_eager_add_metric',\n",
       " '_eager_losses',\n",
       " '_expects_training_arg',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_feed_loss_fns',\n",
       " '_feed_output_names',\n",
       " '_feed_output_shapes',\n",
       " '_feed_sample_weights',\n",
       " '_feed_targets',\n",
       " '_flatten',\n",
       " '_function_kwargs',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_callback_model',\n",
       " '_get_existing_metric',\n",
       " '_get_node_attribute_at_index',\n",
       " '_graph',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_metrics',\n",
       " '_handle_per_output_metrics',\n",
       " '_handle_weight_regularization',\n",
       " '_inbound_nodes',\n",
       " '_init_graph_network',\n",
       " '_init_metric_attributes',\n",
       " '_init_set_name',\n",
       " '_init_subclassed_network',\n",
       " '_input_coordinates',\n",
       " '_input_layers',\n",
       " '_inputs_from_call_args',\n",
       " '_insert_layers',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_is_layer',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_layer_call_argspecs',\n",
       " '_layers',\n",
       " '_layers_by_depth',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_loss_weights_list',\n",
       " '_losses',\n",
       " '_make_callback_model',\n",
       " '_make_execution_function',\n",
       " '_make_predict_function',\n",
       " '_make_test_function',\n",
       " '_make_train_function',\n",
       " '_maybe_build',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_epoch_from_ckpt',\n",
       " '_metrics',\n",
       " '_metrics_tensors',\n",
       " '_mixed_precision_policy',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_nested_inputs',\n",
       " '_nested_outputs',\n",
       " '_network_nodes',\n",
       " '_no_dependency',\n",
       " '_nodes_by_depth',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_outbound_nodes',\n",
       " '_output_coordinates',\n",
       " '_output_layers',\n",
       " '_output_loss_metrics',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_per_output_metrics',\n",
       " '_per_output_weighted_metrics',\n",
       " '_preload_simple_restoration',\n",
       " '_prepare_output_masks',\n",
       " '_prepare_sample_weights',\n",
       " '_prepare_skip_target_masks',\n",
       " '_prepare_total_loss',\n",
       " '_process_target_tensor_for_compile',\n",
       " '_recompile_weights_loss_and_weighted_metrics',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_reuse',\n",
       " '_run_eagerly',\n",
       " '_run_internal_graph',\n",
       " '_sample_weight_modes',\n",
       " '_scope',\n",
       " '_self_name_based_restores',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_set_connectivity_metadata_',\n",
       " '_set_dtype_and_policy',\n",
       " '_set_input_attrs',\n",
       " '_set_inputs',\n",
       " '_set_mask_metadata',\n",
       " '_set_metric_attributes',\n",
       " '_set_output_attrs',\n",
       " '_set_output_names',\n",
       " '_set_per_output_metric_attributes',\n",
       " '_setattr_tracking',\n",
       " '_should_compute_mask',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_standardize_user_data',\n",
       " '_symbolic_add_metric',\n",
       " '_symbolic_call',\n",
       " '_targets',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_layers',\n",
       " '_track_trackable',\n",
       " '_trackable_saver',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_training_endpoints',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_unpack_validation_data',\n",
       " '_update_sample_weight_modes',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " '_validate_compile_param_for_distribution_strategy',\n",
       " '_validate_graph_inputs_and_outputs',\n",
       " '_validate_or_infer_batch_size',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'dynamic',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'loss_functions',\n",
       " 'loss_weights',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'run_eagerly',\n",
       " 'sample_weight_mode',\n",
       " 'sample_weights',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'total_loss',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-1ac428716ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "model.output(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> (1, 65)\n",
      "(1, 64)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-b54c0cfb6eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#tf.print(tape.jacobian(pred, x_tf))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(tape.gra,dient(pred, x_tf))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdiv\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "for i in range(96):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_tf = tf.convert_to_tensor(np.expand_dims(features[i,:],axis=0))\n",
    "        print(type(x_tf))\n",
    "        tape.watch(x_tf)\n",
    "        f = (x_tf-fsub)/fdiv\n",
    "        print(type(f))\n",
    "        p = model.predict_on_batch(f)\n",
    "        print(type(p))\n",
    "        p = (p/tdiv)+tsub\n",
    "        print(type(p), p.shape)\n",
    "        print(x_tf.shape)\n",
    "        pred = tf.convert_to_tensor(p)\n",
    "        print(type(pred))\n",
    "        out_i = pred[0, i]\n",
    "      \n",
    "        \n",
    "        \n",
    "    #tf.print(tape.jacobian(pred, x_tf))\n",
    "    #print(tape.gra,dient(pred, x_tf))\n",
    "    grads = tape.jacobian(out_i, x_tf).numpy()\n",
    "    J[i, :] = grads/(fdiv*cf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.parallel_for.gradients import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 65)\n",
      "(1, 64)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(96):\n",
    "    f = features[i]\n",
    "    f=f.reshape(-1,1)\n",
    "    x = np.reshape(f, (1,64))\n",
    "    f = (x_tf-fsub)/fdiv\n",
    "    p = model.predict_on_batch(f)\n",
    "    p = (p/tdiv)+tsub\n",
    "    \n",
    "    J=jacobian(tf.convert_to_tensor(p),tf.convert_to_tensor(x))\n",
    "    if i == 0:\n",
    "        print(p.shape)\n",
    "        print(x.shape)\n",
    "        print(J)\n",
    "        print(J)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.parallel_for.gradients import jacobian\n",
    "J=jacobian(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_tensorflow(x):    \n",
    "    jacobian_matrix = []\n",
    "    for m in range(Neuron_Out):\n",
    "        # We iterate over the M elements of the output vector\n",
    "        grad_func = tf.gradients(model_ANN.output[:, m],model_ANN.input)\n",
    "        gradients = sess.run(grad_func, feed_dict={model_ANN.input: x})  # Removed x.reshape((1, x.size)) as reshape is not required bcoz dense accepts the shape\n",
    "        jacobian_matrix.append(gradients[0][0,:])\n",
    "\n",
    "    return np.array(jacobian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(96):\n",
    "    f = features[i]\n",
    "    f=f.reshape(-1,1)\n",
    "    x = np.reshape(f, (1,64))\n",
    "    f = (x_tf-fsub)/fdiv\n",
    "    p = model.predict_on_batch(f)\n",
    "    p = (p/tdiv)+tsub\n",
    "    \n",
    "    J=jacobian(tf.convert_to_tensor(p),tf.convert_to_tensor(x))\n",
    "    if i == 0:\n",
    "        print(p.shape)\n",
    "        print(x.shape)\n",
    "        print(J)\n",
    "        print(J)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradients = sess.run(grad_func, feed_dict={model.input: x.reshape((1, x.size))})\n",
    "#        jacobian_matrix.append(gradients[0][0,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
